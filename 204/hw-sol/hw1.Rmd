---
title: "Homework 1"
author: "Mary Silva, Wyara Moura Silva, and Peter Trubey"
date: "10/16/2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Chapter 1

```{r, echo=FALSE, include=FALSE}
packages = c('MASS','dplyr','lattice','dice')
lapply(packages, require, character.only = TRUE)
```

###Question 6
```{r}
library(htmltab)
table_url = paste(
  'http://en.wikipedia.org',
  'wiki',
  'Heights_of_presidents_and_presidential_candidates_of_the_United_States',
  sep = '/'
  )
table = htmltab(table_url, which = 4)
table_names = c(
  'election', 'winner', 'trash1', 'height_win',
  'opponent', 'trash2', 'height_lose',
  'trash3','height_diff'
)
```
```{r}
names(table) = table_names
table = table[
  1:which(table$election == '1948'),
  -which(names(table) %in% c('trash1','trash2','trash3'))
  ]
table$height_win = as.numeric(gsub('[^0-9]','',table$height_win))
table$height_lose = as.numeric(gsub('[^0-9]','',table$height_lose))
table$height_diff = as.numeric(gsub('[^0-9]','',table$height_diff))

min_height = min(table[c('height_win','height_lose')])
max_height = max(table[c('height_win','height_lose')])
plot_lims = c(min_height, max_height)
```

```{r}
plot(
  height_lose ~ height_win, 
  data = table, 
  xlim = plot_lims, ylim = plot_lims,
  main = 'Height of Elected vs Opponent \n in Presidential Elections, 1948 - Present',
  xlab = 'Height of Elected (cm)', ylab = 'Height of Opponent (cm)',
  pch = 8, col = 4
  )
abline(0,1,col = 2)
```

The plot in the wikipedia article includes additional text, additional boundary lines (indicating where one party was shorter or taller than the other, in ranges of 10, clearly labelled), as well as a grid and background shading.  It's not clear that these things add anything to the plot in terms of ease of consumption.

The wikipedia article plot also includes a longer range of time.  I used the range 1948 to present, because that was what was used in example 1.2, and it made data cleaning easier when pulling from the wikipedia table.

###Question 7
```{r}
q1.7_answerer = function(n, lambda){
  data = rpois(n, lambda = lambda)
  freqs = table(data)
  actual = freqs / n
  theoretical = dpois(0:max(data), lambda = lambda)
  # Output
  print(freqs)
  print(c(Mean = mean(data), Variance = var(data)))
  print(cbind(actual, theoretical))
}
```

For $n = 1000$

```{r}
q1.7_answerer(1e3, lambda = 0.61)
```

For $n = 10000$: 

```{r}
q1.7_answerer(1e4, lambda = 0.61)
```

###Question 8
```{r}
q1.8_answerer = function(n, lambda){
  data = rpois(n, lambda = lambda)
  freqs = table(data)
  actual_d = freqs / n
  actual_c = cumsum(actual_d)
  theoretical_d = dpois(0:max(data), lambda = lambda)
  theoretical_c = ppois(0:max(data), lambda = lambda)
  
  df = data.frame(freqs, actual_d, theoretical_d, actual_c, theoretical_c)
  df = df[,-3]
  names(df) = c('Value','Frequency','EmpDist','TheoryDist','EmpCumDist','TheoryCumDist')
  ## Output
  print(df)
}
```


For $n=1000$

```{r}
q1.8_answerer(1e3, lambda = 0.61)
```

For $n = 10000$:

```{r}
q1.8_answerer(1e4, lambda = 0.61)
```


##Chapter 2

###Question 2
````{r}
data(iris)
iris %>% 
  group_by(Species) %>% 
  summarize(
    SepalW.avg = mean(Sepal.Width),
    SepalL.avg = mean(Sepal.Length),
    PetalW.Avg = mean(Petal.Width),
    PetalL.avg = mean(Petal.Length)
    )

```

###Question 3
```{r}
data(mtcars)
head(mtcars)
#?mtcars
attach(mtcars)
variables1 = mtcars[,-(8:9)]
```

```{r}
boxplot(variables1, main = "Boxplot")
```

The boxplot is not very easy to interpret, so we try taking the log of the quantitative variables and produce a second boxplot.

```{r}
log_variables = log(variables1)
boxplot(log_variables, main = "Boxplot of log scale")
```

The above boxplot is simpler to interpret. But each of the variables are represented/measured on completely different scales, so this plot isnt very useful. Next we look at the pairs plot:

```{r}
pairs(variables1)
```

Some of the variables in the pairs plot appear to have a linear relationship. For instance mpg and displacement, mph and weight, weight and displacement, weight and rear axle ratio, weight and gross horsepower all have a possible linear relationship.

###Question 4
```{r, include=F}
library(MASS)
data(mammals)
```
```{r}
mammals$r = mammals$brain/mammals$body
mammals = mammals[order(mammals$r, decreasing = TRUE),]
```

Mammals with largest ratio of brain to body size:
```{r}
head(mammals)
```

Mammals with smallest ratio of brain to body size:
```{r}
tail(mammals)
```

###Question 5
```{r, echo=T}
par(mfrow = c(1,2))
plot(body ~ r, data = mammals)
plot(log(body) ~ log(r), data = mammals)
par(mfrow = c(1,1))
```

###Question 6
```{r, echo=T}
lhdiff = diff(LakeHuron)
par(mfrow = c(1,2))
plot(LakeHuron)
plot(lhdiff)
```

The mean does appear to change with respect to time during the years from 1880 to 1900, but we don't have any indication of what came before 1880, so that might be a premature conclusiojn.  It appears that the mean may have settled down post 1920, but the variance seems to be getting increasingly more erratic.

After taking the first difference, the mean has stabilized.

###Question 7

```{r, echo=T}
q2.7_answerer = function(n,m){
  random_numbers = matrix(runif(n*m, min = 0, max = 1), ncol = m)
  print('Column Means')
  print(apply(random_numbers,2,mean))
  print('Covariance Matrix')
  print(var(random_numbers))
  print('Diagonal of Covariance Matrix')
  print(diag(var(random_numbers)))
  print('Pairwise Correlation Matrix')
  print(cor(random_numbers))
  #cloud(z ~ x + y, data = random_numbers)
  random_means = as.matrix(random_numbers) %*% rep(1,m) / m
  truehist(random_means)
  curve(dnorm(x, 1/2, sqrt(1/(12*m))), col = 'red', lwd = 2, add = TRUE)
}
```

```{r}
q2.7_answerer(400,3)
```

###Question 8

```{r,echo=T}
q2.7_answerer(400,10)
```

The Central Limit Theorem tells us that as the sample size increases, the distribution of the sample means will tend more and more towards a normal distribution.

###Question 12
```{r}
mammals = mammals[order(mammals$brain, decreasing = TRUE),]
```

Mammals with largest brain size:
```{r}
head(mammals)
```

Mammals with smallest brain size:
```{r}
tail(mammals)
```

###Question 13
```{r, echo=T}
data(mammals)

plot(mammals$body,mammals$brain,xlab="body", ylab="brain", ylim = c(-1000,6000), 
     xlim = c(-1000,7000))

y = mammals[c("Cat", "Cow", "Human"), ]
polygon(y)
text(y, rownames(y), adj=c(1, .5))
```

The scatterplot in figure 2.19 is easier to see and interpret since it is on the log-log scale. The observations on this plot with the original scaling are too close.

##Chapter 3
###Question 2
```{r}
die1 = sample(1:6, 1000, replace = TRUE)
die2 = sample(1:6, 1000, replace = TRUE)
die.sum = die1 + die2
print(
  data.frame(
    Sum = 2:12,
    Frequency = as.vector(table(die.sum)),
    EmpProb = as.vector(table(die.sum)/1000),
    AbsProb = getSumProbs(ndicePerRoll = 2,nsidesPerDie = 6)$probabilities[,2]
    )
  )
```


###Question 3
```{r}
#(a)
pujols = data.frame(
  nhits = c('0', '1', '2', '3+'),
  freq = c(17,31,17,5),
  expected = dbinom(c(0,1,2,3), size = 4, p = 0.312)
  )
pujols[4,3] = 1-sum(pujols[1:3,3]) # fix for "3 or more"
chisq.test(pujols$freq, p = pujols$expected)
```

\begin{align*}
H_0 &: \text{the counts follow binomial(4,3.12) distribution}\\
H_a &: \text{the counts do not follow binomial(4,3.12) distribution}
\end{align*}
From the R output, there is not enough evidence to reject the null hypothesis that Pujol's batting follows a binomial distribution, with $p = 0.312$.

```{r}
#(b)
pujols = data.frame(
  nhits = c('0', '1', '2', '3+'),
  freq = c(5,6,4,11),
  expected = dbinom(c(0,1,2,3), size = 5, p = 0.312)
  )
pujols[4,3] = 1-sum(pujols[1:3,3]) # fix for "3 or more"
chisq.test(pujols$freq, p = pujols$expected)
```

\begin{align*}
H_0 &: \text{the counts follow a binomial(5, 0.312) distribution}\\
H_a &: \text{the counts do not follow a binomial(5, 0.312) distribution}
\end{align*}

There is strong evidence to reject the hypothesis that Pujol's batting follows a binomial distribution, with $p = 0.007068$.

###Question 4
```{r,include=F}
library(data.table)
```
```{r}
twins=fread('http://personal.bgsu.edu/~mrizzo/Rx/Rx-data/twins.txt', 
            header=TRUE, sep=",", na.strings=".")
#twins$AGE
#twins$HRWAGEL

c.age = cut(twins$AGE, breaks=c(0,30, 40, 50,80))
P1=table(c.age)
P2=prop.table(P1)
barplot(t(P2), ylim=c(0, 1), ylab="Proportion", legend.text=dimnames(P2)$c.age,
        args.legend=list(x = "top"))
```

###Question 5
```{r}
#(a)
c.age = cut(twins$AGE, breaks=c(0,30, 40, 50,80))
c.wagel = cut(twins$HRWAGEL, c(0, 7, 13, 20, 150))
table(c.age)
table(c.wagel)
```

```{r}
#(b)
taw=table(c.age,c.wagel)
taw
```

```{r}
#(c)
prop.table(taw, margin=1)

```


```{r}
#(d)
P=prop.table(taw, margin=1)
barplot(t(P), ylim=c(0, 2.5), ylab="Proportion", legend.text=dimnames(P)$c.wagel, 
        args.legend=list(x = "top"))

barplot(t(P), ylim=c(0, 1.6), beside=T, legend.text=dimnames(P)$c.wagel, 
        args.legend=list(x="topleft"), ylab="Proportion")

#(e)
```
The twins aged between (0,30] have the lowest hourly wages, and the twins aged between (40,50] tend to have higher hourly wages. There is no clear relation about the older the twins are the hourly wages are higher or vice versa


###Question 6
```{r}
#(a)
tawt=table(c.age,c.wagel)
S = chisq.test(tawt)
print(S)
```
```{r}
testqs=sum((tawt - S$expected)^2 / S$expected)
1 - pchisq(testqs, df=9)

```
We perform a test of independence where
\begin{align*}
H_0 &: \text{ age and wage are independent}\\
H_a &: \text{ age and wage are not independent}
\end{align*}

From the R output, we have a very small p-value which is strong evidence to reject the null hypothesis in favor of the alternative hypothesis. We conclude that age and wage are dependent. 

```{r}
S$expected
```

We should note that some of the expected values are less than 5, which could indicate that the the Chi-square test of independence is not appropriate. R gives us this warning output. Fisher's exact test may be an alternative. 




```{r}
#b)
S$residuals
```


```{r}
#(c)
mosaicplot(tawt, shade=TRUE, main = "Mosaic plot of the extreme residuals", ylab = "Wage", 
           xlab = "Age", las = 1)

```

```{r}
#(d)
```
The residuals of the cell containing age less than 30 and wage greater than 20 exceeds 2 in absolute value. This means that fewer people under 30 are earning wages over \$20 than expected under the independence model. Also, the residuals of the cell containing ages 40-50 and wage greater than 20 exceeds 2 in absolute value. This means that more 40-50 year olds are earning wages greater than \$20 than expected under the independence model.

###Question 7
```{r}
#a)
die1=sample(6,1000, replace=TRUE)
die2=sample(6,1000, replace=TRUE)
```

```{r}
#b)
max.rolls=pmax(die1,die2)
sum.rolls=die1+die2
```

```{r}
#(c) 
```
The contingency table of the maximum roll and sum of rolls is:
```{r}
(tp=table(max.rolls,sum.rolls))

```

```{r}
#(d) 
```
We use a barplot to explore the relationship between the maximum roll and the sum of rolls:


```{r}
barplot(t(tp),legend.text=dimnames(tp)$sum.rolls, args.legend=list(x = "topleft"),ylim=c(0, 700))
```

###Question 8
```{r}
#(a)
pidigits = read.table("http://www.itl.nist.gov/div898/strd/univ/data/PiDigits.dat",skip=60)
(tpi=table(pidigits))
```

```{r}
#(b)
barplot(t(tpi))
```

```{r}
#(c)
```
We construct a hypothesis test
\begin{align*}
H_0 &: \text{ the digits 1 through 9 are equally probably in the digits of} \pi\\
H_1 &: \text{ the digits 1 through 9 are not equally probable in the digits of} \pi
\end{align*}

```{r}
(spi=chisq.test(tpi))
```

Based on the p-value, there is not enough evidence to reject the null hypothesis. We conclude that the digits 1 through 9 are equally probably in the digits of $\pi$.
```{r}
spi$expected
```


